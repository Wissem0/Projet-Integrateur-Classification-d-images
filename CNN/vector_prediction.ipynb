{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np \n",
    "import joblib\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import sys\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_prediction(prediction_score):\n",
    "    s = \"\"\n",
    "    for i, label in enumerate(features_str):\n",
    "        pred = prediction_score[i][0][0]\n",
    "        s += f\"{label}: predicted {1 if pred > 0.5 else 0} ({format(pred, '.4f')})\"\n",
    "        s +=\"\\n\"\n",
    "    return s \n",
    "\n",
    "def display_image(image,s):\n",
    "    plt.imshow(image)\n",
    "    plt.title(s)\n",
    "    plt.figure()\n",
    "    \n",
    "def open_images(inference_folder: str) -> np.ndarray:\n",
    "    images = []\n",
    "    for img in os.listdir(inference_folder):\n",
    "        img_location = os.path.join(inference_folder, img)  \n",
    "        with Image.open(img_location) as img:  \n",
    "            img = np.array(img)\n",
    "            img = img[:, :, :3]\n",
    "            img = np.expand_dims(img, axis=0)  \n",
    "        images.append(img)\n",
    "    images_array = np.vstack(images) \n",
    "    return images_array\n",
    "\n",
    "def resize(path, dirs, resized_path):\n",
    "    for item in dirs:\n",
    "        print(item)\n",
    "        if os.path.isfile(path+item):\n",
    "            im = Image.open(path+item)\n",
    "            im = im.convert('RGB')\n",
    "            f, e = os.path.splitext(path+item)\n",
    "            imResize = im.resize((220,220), Image.ANTIALIAS)\n",
    "            imResize.save(resized_path + item + '_resized.jpg', 'JPEG', quality=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321747370_1579985539139773_9125491476305201953_n.jpg\n"
     ]
    }
   ],
   "source": [
    "features_str = ['Mouth_Slightly_Open','Smiling','Wearing_Lipstick','High_Cheekbones','Male','Heavy_Makeup','Wavy_Hair','Oval_Face','Pointy_Nose','Arched_Eyebrows','Big_Lips','Black_Hair''Big_Nose','Young','Straight_Hair','Brown_Hair','Bags_Under_Eyes','Wearing_Earrings','No_Beard','Bangs','Blond_Hair','Chubby','Bald']\n",
    "\n",
    "path = \"./upload_image/\"\n",
    "dirs = os.listdir( path )\n",
    "resized_path = \"./uploaded_image_resized/\"\n",
    "resize(path, dirs, resized_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.json', 'r') as f: \n",
    "    json = f.read() \n",
    "model = model_from_json(json, custom_objects={'KerasLayer': hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 113ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Mouth_Slightly_Open', 0),\n",
       " ('Smiling', 0),\n",
       " ('Wearing_Lipstick', 1),\n",
       " ('High_Cheekbones', 1),\n",
       " ('Male', 1),\n",
       " ('Heavy_Makeup', 1),\n",
       " ('Wavy_Hair', 1),\n",
       " ('Oval_Face', 1),\n",
       " ('Pointy_Nose', 1),\n",
       " ('Arched_Eyebrows', 0),\n",
       " ('Big_Lips', 0),\n",
       " ('Black_HairBig_Nose', 1),\n",
       " ('Young', 0),\n",
       " ('Straight_Hair', 1),\n",
       " ('Brown_Hair', 0),\n",
       " ('Bags_Under_Eyes', 1),\n",
       " ('Wearing_Earrings', 0),\n",
       " ('No_Beard', 1),\n",
       " ('Bangs', 1),\n",
       " ('Blond_Hair', 1),\n",
       " ('Chubby', 1),\n",
       " ('Bald', 1)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = open_images(resized_path)\n",
    "c=0\n",
    "prediction_vector = []\n",
    "for image in images:\n",
    "    img_batch = np.expand_dims(image, axis=0)\n",
    "    normalizedData = (img_batch-np.min(img_batch))/(np.max(img_batch)-np.min(img_batch))\n",
    "    prediction_score= model.predict(normalizedData)\n",
    "    \n",
    "    for i, label in enumerate(features_str):\n",
    "        pred = 1 if prediction_score[i][0][0] > 0.5 else 0 \n",
    "        prediction_vector.append((label,pred))\n",
    "prediction_vector       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_file = open(\"vector.txt\", \"w\")\n",
    "string_vector = str(prediction_vector)\n",
    "vector_file.write(string_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
